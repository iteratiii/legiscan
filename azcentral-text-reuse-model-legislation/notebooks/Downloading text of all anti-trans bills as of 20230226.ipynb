{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJubItawxK15"
   },
   "source": [
    "# Downloading bill data from LegiScan\n",
    "\n",
    "- [x]  Using `anti-lgbtq-bills-tracker.csv` , get states and URLs\n",
    "- [ ]  Get the master list for the current legislative session for every state on that list\n",
    "- [ ]  Use the master list for each state to look up all bill IDs using the URLs list\n",
    "- [ ]  Use the bill IDs to find the doc IDs\n",
    "- [ ]  Use the doc IDs to download the bill texts\n",
    "- [ ]  Find a [better PDF-to-text parser](https://www.reddit.com/r/Python/comments/ql4xkf/extract_text_from_pdf/) for reading the bill texts\n",
    "- [ ]  Find a spell checker and look up other ways to clean up the bill texts\n",
    "- [ ]  Throw all the bill texts into one big .txt file\n",
    "- [ ]  Run through spaCy and Tracery with it again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeRyZ07OxK19"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "20iPMIO_xK1-"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import base64\n",
    "import io\n",
    "import glob\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import mimetypes\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from base64 import b64decode\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Getting an absolute path from an interactive shell](https://bobbyhadz.com/blog/python-nameerror-name-file-is-not-defined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U.S. state names : abbreviations dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# United States of America Python Dictionary to translate States,\n",
    "# Districts & Territories to Two-Letter codes and vice versa.\n",
    "#\n",
    "# Canonical URL: https://gist.github.com/rogerallen/1583593\n",
    "#\n",
    "# Dedicated to the public domain.  To the extent possible under law,\n",
    "# Roger Allen has waived all copyright and related or neighboring\n",
    "# rights to this code.  Data originally from Wikipedia at the url:\n",
    "# https://en.wikipedia.org/wiki/ISO_3166-2:US\n",
    "\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "    \"US\": \"US\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swapStateAbbrev(state):\n",
    "    state = us_state_to_abbrev.get(state)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swapStateAbbrev(\"Wisconsin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw__Ve8oxK1_"
   },
   "source": [
    "## pylegiscan\n",
    "\n",
    "To talk to LegiScan's API, we're borrowing some code from [pylegiscan](https://github.com/poliquin/pylegiscan). Since it isn't a package you can install with `pip`, it wound up being easier for distribution to just cut and paste it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKW9dPNHxK1_"
   },
   "outputs": [],
   "source": [
    "# Taken from https://github.com/poliquin/pylegiscan/blob/master/pylegiscan/legiscan.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "# current aggregate status of bill\n",
    "BILL_STATUS = {1: \"Introduced\",\n",
    "               2: \"Engrossed\",\n",
    "               3: \"Enrolled\",\n",
    "               4: \"Passed\",\n",
    "               5: \"Vetoed\",\n",
    "               6: \"Failed/Dead\"}\n",
    "\n",
    "# significant steps in bill progress.\n",
    "BILL_PROGRESS = {1: \"Introduced\",\n",
    "                 2: \"Engrossed\",\n",
    "                 3: \"Enrolled\",\n",
    "                 4: \"Passed\",\n",
    "                 5: \"Vetoed\",\n",
    "                 6: \"Failed/Dead\",\n",
    "                 7: \"Veto Override\",\n",
    "                 8: \"Chapter/Act/Statute\",\n",
    "                 9: \"Committee Referral\",\n",
    "                10: \"Committee Report Pass\",\n",
    "                11: \"Committee Report DNP\"}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Interact with LegiScan API.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# a helpful list of valid legiscan state abbreviations (no Puerto Rico)\n",
    "STATES = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc', 'de', 'fl', 'ga',\n",
    "          'hi', 'ia', 'id', 'il', 'in', 'ks', 'ky', 'la', 'ma', 'md', 'me',\n",
    "          'mi', 'mn', 'mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj', 'nm',\n",
    "          'nv', 'ny', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn', 'tx',\n",
    "          'ut', 'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
    "\n",
    "class LegiScanError(Exception):\n",
    "    pass\n",
    "\n",
    "class LegiScan(object):\n",
    "    BASE_URL = 'http://api.legiscan.com/?key={0}&op={1}&{2}'\n",
    "\n",
    "    def __init__(self, apikey=None):\n",
    "        \"\"\"LegiScan API.  State parameters should always be passed as\n",
    "           USPS abbreviations.  Bill numbers and abbreviations are case\n",
    "           insensitive.  Register for API at http://legiscan.com/legiscan\n",
    "        \"\"\"\n",
    "        # see if API key available as environment variable\n",
    "        if apikey is None:\n",
    "            apikey = config.LEGISCAN_API_KEY\n",
    "        self.key = apikey.strip()\n",
    "\n",
    "    def _url(self, operation, params=None):\n",
    "        \"\"\"Build a URL for querying the API.\"\"\"\n",
    "        if not isinstance(params, str) and params is not None:\n",
    "            params = urlencode(params)\n",
    "        elif params is None:\n",
    "            params = ''\n",
    "        return self.BASE_URL.format(self.key, operation, params)\n",
    "\n",
    "    def _get(self, url):\n",
    "        \"\"\"Get and parse JSON from API for a url.\"\"\"\n",
    "        req = requests.get(url)\n",
    "        if not req.ok:\n",
    "            raise LegiScanError('Request returned {0}: {1}'\\\n",
    "                    .format(req.status_code, url))\n",
    "        data = json.loads(req.content)\n",
    "        if data['status'] == \"ERROR\":\n",
    "            raise LegiScanError(data['alert']['message'])\n",
    "        return data\n",
    "\n",
    "    def get_session_list(self, state):\n",
    "        \"\"\"Get list of available sessions for a state.\"\"\"\n",
    "        url = self._url('getSessionList', {'state': state})\n",
    "        data = self._get(url)\n",
    "        return data['sessions']\n",
    "\n",
    "    def get_dataset_list(self, state=None, year=None):\n",
    "        \"\"\"Get list of available datasets, with optional state and year filtering.\n",
    "        \"\"\"\n",
    "        if state is not None:\n",
    "            url = self._url('getDatasetList', {'state': state})\n",
    "        elif year is not None:\n",
    "            url = self._url('getDatasetList', {'year': year})\n",
    "        else:\n",
    "            url = self._url('getDatasetList')\n",
    "        data = self._get(url)\n",
    "        # return a list of the bills\n",
    "        return data['datasetlist']\n",
    "\n",
    "    def get_dataset(self, id, access_key):\n",
    "        \"\"\"Get list of available datasets, with optional state and year filtering.\n",
    "        \"\"\"\n",
    "        url = self._url('getDataset', {'id': id, 'access_key': access_key})\n",
    "        data = self._get(url)\n",
    "        # return a list of the bills\n",
    "        return data['dataset']\n",
    "      \n",
    "    def get_master_list(self, state=None, session_id=None):\n",
    "        \"\"\"Get list of bills for the current session in a state or for\n",
    "           a given session identifier.\n",
    "        \"\"\"\n",
    "        if state is not None:\n",
    "            url = self._url('getMasterList', {'state': state})\n",
    "        elif session_id is not None:\n",
    "            url = self._url('getMasterList', {'id': session_id})\n",
    "        else:\n",
    "            raise ValueError('Must specify session identifier or state.')\n",
    "        data = self._get(url)\n",
    "        # return a list of the bills\n",
    "        return [data['masterlist'][i] for i in data['masterlist']]\n",
    "\n",
    "    def get_bill(self, bill_id=None, state=None, bill_number=None):\n",
    "        \"\"\"Get primary bill detail information including sponsors, committee\n",
    "           references, full history, bill text, and roll call information.\n",
    "\n",
    "           This function expects either a bill identifier or a state and bill\n",
    "           number combination.  The bill identifier is preferred, and required\n",
    "           for fetching bills from prior sessions.\n",
    "        \"\"\"\n",
    "        if bill_id is not None:\n",
    "            url = self._url('getBill', {'id': bill_id})\n",
    "        elif state is not None and bill_number is not None:\n",
    "            url = self._url('getBill', {'state': state, 'bill': bill_number})\n",
    "        else:\n",
    "            raise ValueError('Must specify bill_id or state and bill_number.')\n",
    "        return self._get(url)['bill']\n",
    "\n",
    "    def get_bill_text(self, doc_id):\n",
    "        \"\"\"Get bill text, including date, draft revision information, and\n",
    "           MIME type.  Bill text is base64 encoded to allow for PDF and Word\n",
    "           data transfers.\n",
    "        \"\"\"\n",
    "        url = self._url('getBillText', {'id': doc_id})\n",
    "        return self._get(url)['text']\n",
    "\n",
    "    def get_amendment(self, amendment_id):\n",
    "        \"\"\"Get amendment text including date, adoption status, MIME type, and\n",
    "           title/description information.  The amendment text is base64 encoded\n",
    "           to allow for PDF and Word data transfer.\n",
    "        \"\"\"\n",
    "        url = self._url('getAmendment', {'id': amendment_id})\n",
    "        return self._get(url)['amendment']\n",
    "\n",
    "    def get_supplement(self, supplement_id):\n",
    "        \"\"\"Get supplement text including type of supplement, date, MIME type\n",
    "           and text/description information.  Supplement text is base64 encoded\n",
    "           to allow for PDF and Word data transfer.\n",
    "        \"\"\"\n",
    "        url = self._url('getSupplement', {'id': supplement_id})\n",
    "        return self._get(url)['supplement']\n",
    "\n",
    "    def get_roll_call(self, roll_call_id):\n",
    "        \"\"\"Roll call detail for individual votes and summary information.\"\"\"\n",
    "        data = self._get(self._url('getRollcall', {'id': roll_call_id}))\n",
    "        return data['roll_call']\n",
    "\n",
    "    def get_sponsor(self, people_id):\n",
    "        \"\"\"Sponsor information including name, role, and a followthemoney.org\n",
    "           person identifier.\n",
    "        \"\"\"\n",
    "        url = self._url('getSponsor', {'id': people_id})\n",
    "        return self._get(url)['person']\n",
    "\n",
    "    def search(self, state, bill_number=None, query=None, year=2, page=1):\n",
    "        \"\"\"Get a page of results for a search against the LegiScan full text\n",
    "           engine; returns a paginated result set.\n",
    "\n",
    "           Specify a bill number or a query string.  Year can be an exact year\n",
    "           or a number between 1 and 4, inclusive.  These integers have the\n",
    "           following meanings:\n",
    "               1 = all years\n",
    "               2 = current year, the default\n",
    "               3 = recent years\n",
    "               4 = prior years\n",
    "           Page is the result set page number to return.\n",
    "        \"\"\"\n",
    "        if bill_number is not None:\n",
    "            params = {'state': state, 'bill': bill_number}\n",
    "        elif query is not None:\n",
    "            params = {'state': state, 'query': query,\n",
    "                      'year': year, 'page': page}\n",
    "        else:\n",
    "            raise ValueError('Must specify bill_number or query')\n",
    "        data = self._get(self._url('search', params))['searchresult']\n",
    "        # return a summary of the search and the results as a dictionary\n",
    "        summary = data.pop('summary')\n",
    "        results = {'summary': summary, 'results': [data[i] for i in data]}\n",
    "        return results\n",
    "\n",
    "    def __str__(self):\n",
    "        return '<LegiScan API {0}>'.format(self.key)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCYYTGAwxK2B"
   },
   "source": [
    "# Connect to LegiScan\n",
    "\n",
    "Using pylegiscan, you just pass your API key to `LegiScan` and you're good to go. I set up an environment variable for mine, but you can also just paste yours at `OR_PUT_YOUR_API_KEY_HERE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrrTxa7kxK2B"
   },
   "outputs": [],
   "source": [
    "import config\n",
    "\n",
    "api_key = config.LEGISCAN_API_KEY\n",
    "legis = LegiScan(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdwQeMfXxK2C"
   },
   "source": [
    "If you wanted to search for bills based on state or text, that's easy to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in my anti-trans bills csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'anti-lgbtq-bills-tracker.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lj/gz81psj55xg1_fm6jfz2vbn80000gn/T/ipykernel_25873/3864598504.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'anti-lgbtq-bills-tracker.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'State'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Number'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'URL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'anti-lgbtq-bills-tracker.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('anti-lgbtq-bills-tracker.csv', usecols=['State','Number','URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Abbreviation'] = df.loc[:,'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns=['State','Abbreviation', 'Number', 'URL'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Abbreviation'] = df['Abbreviation'].map(swapStateAbbrev)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('anti-lgbtq-bills-abbrevs-tracker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bill ID'] = ''\n",
    "df['Bill Text'] = ''\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Get the bill IDs from state data\n",
    "1. Look at the state abbreviation\n",
    "2. Open and load the corresponding filepath to the JSON\n",
    "3. Find the bill ID\n",
    "4. Add it in this df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get bill ID for one bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrv = df['Abbreviation'][0]\n",
    "billnum = df['Number'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath = f\"/Users/gabriel/Documents/GitHub/legiscan/azcentral-text-reuse-model-legislation/notebooks/20230224-legiscan-JSONs/{abbrv}/bill/{billnum}.json\"\n",
    "data = json.load(open(filepath))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bill']['texts'][0]['doc_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get bill ID for all bills\n",
    "SUCCESS! Exported to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('anti-lgbtq-bills-abbrevs-tracker.csv', usecols=['State','Abbreviation','Number','URL','Bill ID','Bill Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbillid(abbrv, billnum):\n",
    "    filepath = f\"/Users/gabriel/Documents/GitHub/legiscan/azcentral-text-reuse-model-legislation/notebooks/20230224-legiscan-JSONs/{abbrv}/bill/{billnum}.json\"\n",
    "    data = json.load(open(filepath))\n",
    "    return data['bill']['bill_id']\n",
    "df['Bill ID'] = df.apply(lambda row: getbillid(row['Abbreviation'],row['Number']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('anti-lgbtq-bills-abbrevs-tracker.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Get doc ID for one bill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrv = df['Abbreviation'][2]\n",
    "billnum = df['Number'][2]\n",
    "filepath = f\"/Users/gabriel/Documents/GitHub/legiscan/azcentral-text-reuse-model-legislation/notebooks/20230224-legiscan-JSONs/{abbrv}/bill/{billnum}.json\"\n",
    "data = json.load(open(filepath))\n",
    "data['bill']['texts'][0]['doc_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Get doc IDs for all bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbackup = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('anti-lgbtq-bills-abbrevs-tracker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['bill']['texts'][0]['doc_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Doc ID'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdocid(abbrv, billnum):\n",
    "    filepath = f\"/Users/gabriel/Documents/GitHub/legiscan/azcentral-text-reuse-model-legislation/notebooks/20230224-legiscan-JSONs/{abbrv}/bill/{billnum}.json\"\n",
    "    data = json.load(open(filepath))\n",
    "    try:\n",
    "        print(abbrv, billnum, data['bill']['texts'][0]['doc_id'])\n",
    "        return int(data['bill']['texts'][0]['doc_id'])\n",
    "    except:\n",
    "        print(abbrv, billnum, \"doc_id not found\")        \n",
    "        return None\n",
    "df['Doc ID'] = df.apply(lambda row: getdocid(row['Abbreviation'],row['Number']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('anti-lgbtq-bills-abbrevs-docids-tracker.csv')\n",
    "dfbackup = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Get bill text for all bills\n",
    "> In progress.\n",
    "I forgot that I need a doc ID for this instead of the bill ID. Durr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbilltext(abbrv, doc_id):\n",
    "    try:\n",
    "        docid = int(doc_id)\n",
    "        billtextinfo = legis.get_bill_text(docid)\n",
    "        print(billtextinfo)\n",
    "        return billtextinfo\n",
    "    except:\n",
    "        print('failure')\n",
    "        return None\n",
    "    print(abbrv, \" \", int(doc_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getbilltext(df['Abbreviation'][1], df['Doc ID'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legis.get_bill(bill_id=df['Bill ID'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = int(df['Doc ID'][57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2674851"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works to get doc when doc_id is an int. God knows why\n",
    "legis.get_bill_text(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Bill Text Info'] = df.apply(lambda row: getbilltext(row['Abbreviation'],row['Doc ID']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbackup = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('anti-lgbtq-bills-abbrevs-docids-billinfo-tracker.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Make a column with the MIME? Or just go right into the text parsing?\n",
    "> I can't brain anymore! Stop here for today (Sunday 2023-02-26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['MIME'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getmime(index):\n",
    "    try:\n",
    "        return df2['Bill Text Info'][index]['mime']\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['MIME'] = df2.apply(lambda row: getmime(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to decode from base64 into PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "def decodepdf(bill_text):\n",
    "    # Define the Base64 string of the PDF file\n",
    "    b64 = bill_text['doc']\n",
    "\n",
    "    # Decode the Base64 string, making sure that it contains only valid characters\n",
    "    bytes = b64decode(b64, validate=True)\n",
    "\n",
    "    # Perform a basic validation to make sure that the result is a valid PDF file\n",
    "    # Be aware! The magic number (file signature) is not 100% reliable solution to validate PDF files\n",
    "    # Moreover, if you get Base64 from an untrusted source, you must sanitize the PDF contents\n",
    "    if bytes[0:4] != b'%PDF':\n",
    "      raise ValueError('Missing the PDF file signature')\n",
    "    \n",
    "    bill_id_name = bill_text['bill_id']\n",
    "    \n",
    "    # Write the PDF contents to a local file\n",
    "    f = open('f'bill_id-'{bill_id_name}.pdf', 'wb')\n",
    "    f.write(bytes)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge it with function to get text from PDF and output it to a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function\n",
    "def decodepdftotext(bill_text):\n",
    "    # Define the Base64 string of the PDF file\n",
    "    b64 = bill_text['doc']\n",
    "\n",
    "    # Decode the Base64 string, making sure that it contains only valid characters\n",
    "    bytes = b64decode(b64, validate=True)\n",
    "\n",
    "    # Perform a basic validation to make sure that the result is a valid PDF file\n",
    "    # Be aware! The magic number (file signature) is not 100% reliable solution to validate PDF files\n",
    "    # Moreover, if you get Base64 from an untrusted source, you must sanitize the PDF contents\n",
    "    if bytes[0:4] != b'%PDF':\n",
    "      raise ValueError('Missing the PDF file signature')\n",
    "    \n",
    "    bill_id_name = bill_text['bill_id']\n",
    "    \n",
    "    # Write the PDF contents to a local file\n",
    "    f = open(f\"bill_id-{bill_id_name}.pdf\", \"wb\")\n",
    "    f.write(bytes)\n",
    "    f.close()\n",
    "    \n",
    "    reader = PdfReader(f\"bill_id-{bill_id_name}.pdf\")\n",
    "    text=\"\"\n",
    "    for n in range(0,len(reader.pages)):\n",
    "        page = reader.pages[n]\n",
    "        text = text + page.extract_text()\n",
    "    g = open(f\"bill_id-{bill_id_name}.txt\", \"w\")\n",
    "    g.write(text)\n",
    "    g.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it for all the bill texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(bill_texts)):\n",
    "    if(bill_texts[i]['mime'] == \"application/pdf\"):\n",
    "        decodepdftotext(bill_texts[i])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I extracted all the text from these PDFs. Now how do I deal with the HTML? Let's make a list of just those so I can deal with them properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(33):\n",
    "    bill_id = bill_texts[i]['bill_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with the HTML-formatted bill texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlbills = []\n",
    "for i in range(0,len(bill_texts)):\n",
    "    if(bill_texts[i]['mime'] == \"text/html\"):\n",
    "        htmlbills.append(bill_texts[i])\n",
    "htmlbills[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "htmlbills[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b64tohtml(bill_text):\n",
    "    # Define the Base64 string of the PDF file\n",
    "    b64 = bill_text['doc']\n",
    "\n",
    "    # Decode the Base64 string, making sure that it contains only valid characters\n",
    "    bytes = b64decode(b64, validate=True)\n",
    "\n",
    "    bill_id_name = bill_text['bill_id']\n",
    "    \n",
    "    # Write the PDF contents to a local file\n",
    "    h = open(f\"bill_id-{bill_id_name}.html\", \"wb\")\n",
    "    print(h)\n",
    "    h.write(bytes)\n",
    "    h.close()\n",
    "    \n",
    "    with open(f\"bill_id-{bill_id_name}.html\") as fp:\n",
    "        soup = BeautifulSoup(fp)\n",
    "    i = open(f\"bill_id-{bill_id_name}.txt\", \"w\")\n",
    "    i.write(soup.get_text())\n",
    "    i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b64tohtml(htmlbills[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(htmlbills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(htmlbills)):\n",
    "    b64tohtml(htmlbills[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_id-1633355.html') as f:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlbills[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b64tohtmlonly(bill_text):\n",
    "    # Define the Base64 string of the PDF file\n",
    "    b64 = bill_text['doc']\n",
    "\n",
    "    # Decode the Base64 string, making sure that it contains only valid characters\n",
    "    bytes = b64decode(b64, validate=True)\n",
    "\n",
    "    bill_id_name = bill_text['bill_id']\n",
    "    \n",
    "    # Write the PDF contents to a local file\n",
    "    h = open(f\"bill_id-{bill_id_name}.html\", \"wb\")\n",
    "    print(h)\n",
    "    h.write(bytes)\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 and 9 are the problematic ones\n",
    "b64tohtmlonly(htmlbills[8])\n",
    "b64tohtmlonly(htmlbills[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bill_id-1633355.html') as f:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_details[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one file to see if it'll work\n",
    "with open(\"billtxts/1632709.txt\", \"rb\") as f:\n",
    "    txt = f.readlines()\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add text from txt files to bill details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(bill_details)):\n",
    "    filename = bill_details[i]['bill_id']\n",
    "    with open(f\"billtxts/{filename}.txt\", \"rb\") as f:\n",
    "        bill_details[i]['text'] = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill_details[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(bill_details[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = bill_details[0].keys()\n",
    "\n",
    "with open('bill_details.csv','w',newline='') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file,keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(bill_details)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More stuff below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the bill info for the first result\n",
    "This is a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bills['results'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the bill text for the first result\n",
    "This is a base64 encoded PDF, as we can see in 'mime':'application/pdf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbilltext = legis.get_bill_text(2631259)\n",
    "print(testbilltext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I struggled with opening this bill text and finally found the solution [here!](https://base64.guru/developers/python/examples/decode-pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Base64 string of the PDF file\n",
    "b64 = testbilltext['doc']\n",
    "\n",
    "# Decode the Base64 string, making sure that it contains only valid characters\n",
    "bytes = b64decode(b64, validate=True)\n",
    "\n",
    "# Perform a basic validation to make sure that the result is a valid PDF file\n",
    "# Be aware! The magic number (file signature) is not 100% reliable solution to validate PDF files\n",
    "# Moreover, if you get Base64 from an untrusted source, you must sanitize the PDF contents\n",
    "if bytes[0:4] != b'%PDF':\n",
    "  raise ValueError('Missing the PDF file signature')\n",
    "\n",
    "# Write the PDF contents to a local file\n",
    "f = open('2631259.pdf', 'wb')\n",
    "f.write(bytes)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, extracting the text from the entire PDF by finding the number of pages and getting their text one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"2631259.pdf\")\n",
    "for n in range(0,len(reader.pages)):\n",
    "    page = reader.pages[n]\n",
    "    text = text + page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = open('2631259.txt', 'w')\n",
    "g.write(text)\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I previously extracted the wrong text, because get_bill_text takes doc_id as the argument and not bill id!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "I think I need to [create a pandas dataframe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.from_records.html#pandas.DataFrame.from_records) to hold all the bills['results'] info, then add an empty column for the bill text, then go through each of the bill IDs and download their text, accounting for each data type (some doc, some txt, some PDF, some HTML? check using the get_bill_text 'mime'). \n",
    "\n",
    "Then I have to clean it up, removing things like the numbers above. Then I can begin to use NLP tools to mess around with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(bills['results'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just realized that bills is only the first 50 results, from the first page of the search query. To get them all I have to iterate through the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MD4HYx0axK2C",
    "outputId": "d96cbfbc-3e2e-4b07-fd7e-91bc62d52702"
   },
   "outputs": [],
   "source": [
    "billslist = []\n",
    "for i in range(1,10):\n",
    "    bills = legis.search(state='ALL', query='biological sex', page=i)\n",
    "    billslist.append(bills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    print(billslist[i]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(billslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billslist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different approach\n",
    "I don't know what's going on with my queries! I did something weird to the page numbers. Maybe it would make more sense to:\n",
    "1. Download the [tracker](https://docs.google.com/spreadsheets/d/1fTxHLjBa86GA7WCT-V6AbEMGRFPMJndnaVGoZZX4PMw/edit#gid=0) as a CSV\n",
    "2. Use the URL to get the state & bill number for each bill\n",
    "3. Use pylegiscan get_bill to get the bill info, including doc ID\n",
    "4. Add it to a pandas dataframe\n",
    "5. Use the doc ID to get_bill_text\n",
    "6. Download the text and add that to the dataframe\n",
    "7. Clean up all the text\n",
    "\n",
    "Or, should I try downloading just a few more for now and see what results when I play with them?\n",
    "\n",
    "Looking at the [code](https://github.com/alliraine/legialerts/blob/main/main.py) used to update the Google Sheet in the first place using the LegiScan API, they pull the legislative session master list and turn that into a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainlist = legis.get_master_list(state=None,session_id=2031)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(mainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[400:425]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibillsdf = pd.read_csv(\"anti-lgbtq-bills-tracker.csv\")\n",
    "antibillsdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibillsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_to_abbrev[\"Alaska\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibillsdf['State'] = antibillsdf['State'].replace(us_state_to_abbrev)\n",
    "antibillsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibillsdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the state abbrev and bill number from the whole CSV\n",
    "statebillnodf = antibillsdf.filter(['State','Number','URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statebillnodf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(antibillsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllist = list(antibillsdf['URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateabbvs = list(antibillsdf['State'])\n",
    "billnos = list(antibillsdf['Number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateabbvs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "billnos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "God this is such a dumb way to do this, but it's the way I know how!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antibillsdf.URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(antibillsdf.URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billinfos = []\n",
    "for i in range(len(antibillsdf.URL)):\n",
    "    if(billnos[i] != \"nan\"):\n",
    "        billinfo = legis.get_bill(bill_id=None, state=stateabbvs[i], bill_number=billnos[i])    \n",
    "        billinfos.append(billinfo)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example code continues below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MD4HYx0axK2C",
    "outputId": "d96cbfbc-3e2e-4b07-fd7e-91bc62d52702"
   },
   "outputs": [],
   "source": [
    "# bills = legis.search(state='tx', query='abortion')\n",
    "# bills['summary'] # how many results did we get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lYvUCqWxK2D"
   },
   "source": [
    "You can also get single bills, one at a time, as long as you know their ID in the LegiScan database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Foo2_xSxK2D",
    "outputId": "bd2cff31-cfd9-4870-a5ed-9807f49528bc"
   },
   "outputs": [],
   "source": [
    "legis.get_bill('1635057')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2[df2.url.isin(urllist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIuIhr1kxK2D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2['url'].isin(antibillsdf['URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BEXByESnxK2E"
   },
   "source": [
    "# LegiScan Datasets\n",
    "\n",
    "It'd take forever to download the bills one at a time, so we take advantage of LegiScan's [datasets](https://legiscan.com/datasets) capability. They're a whole set of bill data for each session of the legislature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkottOFgxK2E",
    "outputId": "f4b0366e-5684-4f67-b9f2-fe0aec00cd94"
   },
   "outputs": [],
   "source": [
    "datasets = legis.get_dataset_list()\n",
    "dataset = legis.get_dataset(datasets[20]['session_id'], datasets[20]['access_key'])\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yr3pjH8dxK2E"
   },
   "source": [
    "They come in a _really_ weird format, though: a [base64-encoded](https://en.wikipedia.org/wiki/Base64) zip file. SO first we need to convert the base64 zipfile into a normal file, then unzip it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aglwoiZBxK2E"
   },
   "outputs": [],
   "source": [
    "z_bytes = base64.b64decode(dataset['zip'])\n",
    "z = zipfile.ZipFile(io.BytesIO(z_bytes))\n",
    "z.extractall(\"./sample-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRspYMM5xK2E"
   },
   "source": [
    "It creates a lot lot lot lot lot of `.json` files. For example, let's take a look at a sample of what we just extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kb50sM74xK2F",
    "outputId": "d103c79b-b3e8-48e9-c9fd-15ff8414e7d5"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "filenames = glob.glob(\"./sample-data/*/*/bill/*\", recursive=True)\n",
    "filenames[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jabC0ysxK2F"
   },
   "source": [
    "Each file has all sorts of information about the bill, but **none of the text of the bill itself!** You can see for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mg2tliZixK2G",
    "outputId": "1960c8ac-1ba6-47d3-aa2d-d588bbadb4ce"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_data = json.load(open(\"./sample-data/AK/2017-2018_30th_Legislature/bill/SCR10.json\"))\n",
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmEAjE5JxK2G"
   },
   "source": [
    "You _can_ download the bill text if you have the ID, but... for some reason we don't do this. I'm going to be honest: I don't remember why. Maybe it's because they're older versions? They're incomplete? I truly have forgetten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l4PfG9QLxK2G"
   },
   "outputs": [],
   "source": [
    "doc = legis.get_bill_text('2015157')\n",
    "contents = base64.b64decode(doc['doc'])\n",
    "with open(\"filename.html\", \"wb\") as file:\n",
    "    file.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g98oco9gxK2G"
   },
   "source": [
    "What we're going to need is the **URL to the published version.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1aIce9JxK2G",
    "outputId": "ea28dd6b-0e21-47e0-9150-ec64c6b2a79f"
   },
   "outputs": [],
   "source": [
    "json_data['bill']['texts'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn7Es_b7xK2H"
   },
   "source": [
    "We're going to need the URL to the published version from _every single one of those JSON files_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWU64XhvxK2H"
   },
   "source": [
    "# Download and extract all of the datasets from LegiScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs2aqlpxxK2H",
    "outputId": "96246a97-8b7a-4142-c186-f260e408e4b6"
   },
   "outputs": [],
   "source": [
    "datasets = legis.get_dataset_list()\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHEuO5_nxK2H"
   },
   "source": [
    "Downloading and extracting all 583 is going to take a while, so we'll use a progress bar from [tqdm](https://github.com/tqdm/tqdm) to keep track of where we're at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d7ce247c10be477e8c20200fcb77e280"
     ]
    },
    "id": "I-Yvm9DcxK2H",
    "outputId": "b33781e5-1e9e-4e8b-e6fe-9ae9e8841b6b"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "total = len(datasets)\n",
    "for dataset in tqdm.tqdm_notebook(datasets):\n",
    "    session_id = dataset['session_id']\n",
    "    access_key = dataset['access_key']\n",
    "    details = legis.get_dataset(session_id, access_key)\n",
    "    z_bytes = base64.b64decode(details['zip'])\n",
    "    z = zipfile.ZipFile(io.BytesIO(z_bytes))\n",
    "    z.extractall(\"./bill_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.index.where(df3[1] == True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.index.isin(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfk9iX8RxK2H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYrIzt9dxK2H"
   },
   "source": [
    "# Converting the many JSON files to single CSV file\n",
    "\n",
    "The data isn't doing us much good sitting around as a zillion json files, so we'll convert them into a CSV file with the pieces of information we're interested in. Those pieces are:\n",
    "\n",
    "* State\n",
    "* Bill title\n",
    "* Bill URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KD3msx6FxK2H",
    "outputId": "e0a1203e-fdba-4a8a-def9-64fc41a6c8c5"
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"bill_data/*/*/bill/*.json\")\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1ucIfxUxK2I",
    "outputId": "0b9ae018-40d8-41c9-d94f-00109cf436db"
   },
   "outputs": [],
   "source": [
    "filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acuDoH5DxK2I"
   },
   "source": [
    "If we want to process over a million rows, it's going to take a while! To speed things up we're going to turn to [swifter](https://github.com/jmcarpenter2/swifter), a package that can parallelize work on pandas dataframes. It's pretty easy to use:\n",
    "\n",
    "**without swifter:**\n",
    "\n",
    "```python\n",
    "df = pd.Series(filenames).apply(process_json)\n",
    "```\n",
    "\n",
    "**with swifter:**\n",
    "\n",
    "```python\n",
    "df = pd.Series(filenames).swifter.apply(process_json)\n",
    "```\n",
    "\n",
    "And it does all the hard work for you! You just use it and hope for the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "523ac203bd664e6f95afe6fd739d209a"
     ]
    },
    "id": "4l6OLysxxK2I",
    "outputId": "ff4c9d04-894c-4579-ac56-2691b4f089b5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import swifter\n",
    "import pandas as pd\n",
    "\n",
    "def process_json(filename):\n",
    "    with open(filename) as file:\n",
    "        bill_data = {}\n",
    "        # We need to do a little string replacing so the \n",
    "        json_str = file.read().replace('\"0000-00-00\"', 'null')\n",
    "        content = json.loads(json_str)['bill']\n",
    "\n",
    "        bill_data['bill_id'] = content['bill_id']\n",
    "        bill_data['code'] = os.path.splitext(os.path.basename(filename))[0]\n",
    "        bill_data['bill_number'] = content['bill_number']\n",
    "        bill_data['title'] = content['title']\n",
    "        bill_data['description'] = content['description']\n",
    "        bill_data['state'] = content['state']\n",
    "        bill_data['session'] = content['session']['session_name']\n",
    "        bill_data['filename'] = filename\n",
    "        bill_data['status'] = content['status']\n",
    "        bill_data['status_date'] = content['status_date']\n",
    "\n",
    "        try:\n",
    "            bill_data['url'] = content['texts'][-1]['state_link']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return pd.Series(bill_data)\n",
    "\n",
    "df = pd.Series(filenames).swifter.apply(process_json)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCaDdHLAxK2I"
   },
   "source": [
    "And now we'll save it to prepare for the next step: **inserting it into a database.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uMa0A00xK2I"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/bills-with-urls.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqHXgLPmxK2I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
